{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./DATA/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           xx   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n\n   X172  X173  X174  X175  X176  X177  X178  y  \n0   -31   -77  -103  -127  -116   -83   -51  4  \n1   146   152   157   156   154   143   129  1  \n2    48    19   -12   -30   -35   -35   -36  5  \n3   -80   -77   -85   -77   -72   -69   -65  5  \n4   -12   -32   -41   -65   -83   -89   -73  5  \n\n[5 rows x 180 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xx</th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>...</th>\n      <th>X170</th>\n      <th>X171</th>\n      <th>X172</th>\n      <th>X173</th>\n      <th>X174</th>\n      <th>X175</th>\n      <th>X176</th>\n      <th>X177</th>\n      <th>X178</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>X21.V1.791</td>\n      <td>135</td>\n      <td>190</td>\n      <td>229</td>\n      <td>223</td>\n      <td>192</td>\n      <td>125</td>\n      <td>55</td>\n      <td>-9</td>\n      <td>-33</td>\n      <td>...</td>\n      <td>-17</td>\n      <td>-15</td>\n      <td>-31</td>\n      <td>-77</td>\n      <td>-103</td>\n      <td>-127</td>\n      <td>-116</td>\n      <td>-83</td>\n      <td>-51</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>X15.V1.924</td>\n      <td>386</td>\n      <td>382</td>\n      <td>356</td>\n      <td>331</td>\n      <td>320</td>\n      <td>315</td>\n      <td>307</td>\n      <td>272</td>\n      <td>244</td>\n      <td>...</td>\n      <td>164</td>\n      <td>150</td>\n      <td>146</td>\n      <td>152</td>\n      <td>157</td>\n      <td>156</td>\n      <td>154</td>\n      <td>143</td>\n      <td>129</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>X8.V1.1</td>\n      <td>-32</td>\n      <td>-39</td>\n      <td>-47</td>\n      <td>-37</td>\n      <td>-32</td>\n      <td>-36</td>\n      <td>-57</td>\n      <td>-73</td>\n      <td>-85</td>\n      <td>...</td>\n      <td>57</td>\n      <td>64</td>\n      <td>48</td>\n      <td>19</td>\n      <td>-12</td>\n      <td>-30</td>\n      <td>-35</td>\n      <td>-35</td>\n      <td>-36</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>X16.V1.60</td>\n      <td>-105</td>\n      <td>-101</td>\n      <td>-96</td>\n      <td>-92</td>\n      <td>-89</td>\n      <td>-95</td>\n      <td>-102</td>\n      <td>-100</td>\n      <td>-87</td>\n      <td>...</td>\n      <td>-82</td>\n      <td>-81</td>\n      <td>-80</td>\n      <td>-77</td>\n      <td>-85</td>\n      <td>-77</td>\n      <td>-72</td>\n      <td>-69</td>\n      <td>-65</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>X20.V1.54</td>\n      <td>-9</td>\n      <td>-65</td>\n      <td>-98</td>\n      <td>-102</td>\n      <td>-78</td>\n      <td>-48</td>\n      <td>-16</td>\n      <td>0</td>\n      <td>-21</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>-12</td>\n      <td>-32</td>\n      <td>-41</td>\n      <td>-65</td>\n      <td>-83</td>\n      <td>-89</td>\n      <td>-73</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 180 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head() #each row represents one second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0, 1]\n"
    }
   ],
   "source": [
    "df = df.sample(frac=1) #shuffle dataset\n",
    "data = df.drop(['y', 'xx'], axis=1).to_numpy()\n",
    "labels = df['y'].to_numpy()\n",
    "\n",
    "#map labels to binary - class 1 has epilepsy only. so class 1 for yes epilepsy, 0 for no\n",
    "for (i,l) in enumerate(labels):\n",
    "    if l != 1:\n",
    "        labels[i] = 0\n",
    "all_labels = list(set(df['y'].unique().tolist()))\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.linalg.norm(data)\n",
    "data = data/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(data) == len(labels))\n",
    "train, validate, test = np.split(data, [int(.6*len(data)), int(.8*len(data))])\n",
    "train_labels, validate_labels, test_labels = np.split(labels, [int(.6*len(labels)), int(.8*len(labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(6900, 178)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "TIMESTEPS = 1\n",
    "INPUT_SHAPE = (TIMESTEPS, num_columns-2)\n",
    "DROPOUT = 0.2\n",
    "UNITS = 256\n",
    "ACTIVATION = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    input = layers.Input(shape=INPUT_SHAPE)\n",
    "    print(input.shape)\n",
    "    cell = layers.LSTMCell(32)\n",
    "    rnn = layers.RNN(cell)(input)\n",
    "    fc1 = layers.Dense(64, activation='relu')(rnn)\n",
    "    output = layers.Dense(1)(fc1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(None, 1, 178)\nModel: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 1, 178)]          0         \n_________________________________________________________________\nrnn (RNN)                    (None, 32)                27008     \n_________________________________________________________________\ndense (Dense)                (None, 64)                2112      \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 29,185\nTrainable params: 29,185\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshape(input):\n",
    "    size, features = input.shape\n",
    "    return input.reshape(size, TIMESTEPS, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = Reshape(train), Reshape(validate), Reshape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(6900, 1, 178)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n108/108 - 1s - loss: 0.5767 - accuracy: 0.8022 - val_loss: 0.5060 - val_accuracy: 0.7965\nEpoch 2/10\n108/108 - 0s - loss: 0.4974 - accuracy: 0.8022 - val_loss: 0.5053 - val_accuracy: 0.7965\nEpoch 3/10\n108/108 - 0s - loss: 0.4975 - accuracy: 0.8022 - val_loss: 0.5055 - val_accuracy: 0.7965\nEpoch 4/10\n108/108 - 0s - loss: 0.4972 - accuracy: 0.8022 - val_loss: 0.5054 - val_accuracy: 0.7965\nEpoch 5/10\n108/108 - 0s - loss: 0.4974 - accuracy: 0.8022 - val_loss: 0.5052 - val_accuracy: 0.7965\nEpoch 6/10\n108/108 - 0s - loss: 0.4970 - accuracy: 0.8022 - val_loss: 0.5050 - val_accuracy: 0.7965\nEpoch 7/10\n108/108 - 0s - loss: 0.4970 - accuracy: 0.8022 - val_loss: 0.5049 - val_accuracy: 0.7965\nEpoch 8/10\n108/108 - 0s - loss: 0.4967 - accuracy: 0.8022 - val_loss: 0.5049 - val_accuracy: 0.7965\nEpoch 9/10\n108/108 - 0s - loss: 0.4969 - accuracy: 0.8022 - val_loss: 0.5052 - val_accuracy: 0.7965\nEpoch 10/10\n108/108 - 0s - loss: 0.4967 - accuracy: 0.8022 - val_loss: 0.5050 - val_accuracy: 0.7965\n"
    }
   ],
   "source": [
    "history = model.fit(train, train_labels, \n",
    "epochs=EPOCHS, \n",
    "validation_data=(validate, validate_labels), \n",
    "batch_size=BATCH_SIZE, \n",
    "verbose=2, \n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./Models/LSTM1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_data,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(np.expand_dims(test_data[0], axis=0))\n",
    "# class_labels.int2str(np.argmax(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}